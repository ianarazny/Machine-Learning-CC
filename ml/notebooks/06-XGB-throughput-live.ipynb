{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "from collections import deque, defaultdict\n",
    "from dataclasses import dataclass, field\n",
    "from datetime import timedelta\n",
    "from urllib.parse import quote_plus\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dateutil import tz\n",
    "from sqlalchemy import create_engine, text\n",
    "import joblib\n",
    "\n",
    "# ===================== CONFIG =====================\n",
    "DB_HOST = os.getenv(\"DB_HOST\")\n",
    "DB_PORT = os.getenv(\"DB_PORT\")\n",
    "DB_NAME = os.getenv(\"DB_NAME\")\n",
    "DB_USER = os.getenv(\"DB_USER\")\n",
    "DB_PASS = quote_plus(os.getenv(\"DB_PASSWORD\", \"\"))\n",
    "\n",
    "ENGINE = create_engine(f\"postgresql+psycopg2://{DB_USER}:{DB_PASS}@{DB_HOST}:{DB_PORT}/{DB_NAME}\")\n",
    "\n",
    "MODEL_PATH   = os.getenv(\"MODEL_PATH\", \"xgb_bps_h1s_v3.joblib\")  \n",
    "POLL_SECONDS = int(os.getenv(\"POLL_SECONDS\", \"1\"))            \n",
    "WARMUP_SEC   = int(os.getenv(\"WARMUP_SEC\", \"10\"))             \n",
    "SAVE_TO_DB   = os.getenv(\"SAVE_TO_DB\", \"true\").lower() == \"true\"\n",
    "MODEL_VERSION= os.getenv(\"MODEL_VERSION\", \"xgb_bps_h1s_v3\")\n",
    "\n",
    "# mismas FEATURES que usaste al entrenar:\n",
    "FEATURES = [\n",
    "  \"throughput_bps_t\",\"pps_t\",\n",
    "  \"thr_lag1\",\"thr_lag2\",\"thr_lag3\",\"thr_lag5\",\n",
    "  \"pps_lag1\",\"pps_lag2\",\"pps_lag3\",\"pps_lag5\",\n",
    "  \"thr_ma_5\",\"thr_std_5\",\"pps_ma_5\",\"thr_slope5\"\n",
    "]\n",
    "\n",
    "# ================== ESTADO POR FLUJO ==================\n",
    "@dataclass\n",
    "class FlowState:\n",
    "    thr: deque = field(default_factory=lambda: deque(maxlen=5))   # throughput_bps_t\n",
    "    pps: deque = field(default_factory=lambda: deque(maxlen=5))   # pps_t\n",
    "    ts : deque = field(default_factory=lambda: deque(maxlen=5))\n",
    "    last_packets: int | None = None\n",
    "    last_ts: pd.Timestamp | None = None\n",
    "\n",
    "    def update_from_row(self, ts, throughput_bps_t, packets):\n",
    "        \"\"\"Actualiza pps desde 'packets' acumulativo usando deltat para robustez.\"\"\"\n",
    "        ts = pd.Timestamp(ts)  # tz-aware OK\n",
    "        if self.last_packets is not None and self.last_ts is not None:\n",
    "            dt_s = (ts - self.last_ts).total_seconds()\n",
    "            if dt_s > 0 and packets is not None:\n",
    "                dp = max(packets - self.last_packets, 0)\n",
    "                pps_t = dp / dt_s\n",
    "            else:\n",
    "                pps_t = None\n",
    "        else:\n",
    "            pps_t = None\n",
    "\n",
    "        self.last_packets = packets\n",
    "        self.last_ts = ts\n",
    "\n",
    "        # Guardar valores\n",
    "        self.ts.append(ts)\n",
    "        self.thr.append(float(throughput_bps_t) if throughput_bps_t is not None else 0.0)\n",
    "        self.pps.append(float(pps_t) if pps_t is not None else np.nan)\n",
    "\n",
    "    def feature_vector(self):\n",
    "        \"\"\"Construye el vector FEATURES si hay suficiente historia; si no, devuelve None.\"\"\"\n",
    "        if len(self.thr) < 5 or len(self.pps) < 5:\n",
    "            return None\n",
    "\n",
    "        # Convertir a arrays para cálculos\n",
    "        thr_arr = np.array(self.thr, dtype=float)\n",
    "        pps_arr = np.array(self.pps, dtype=float)\n",
    "\n",
    "        # lags (1,2,3,5) → posiciones desde el final\n",
    "        thr_lag1 = thr_arr[-2]\n",
    "        thr_lag2 = thr_arr[-3]\n",
    "        thr_lag3 = thr_arr[-4]\n",
    "        thr_lag5 = thr_arr[0]\n",
    "\n",
    "        pps_lag1 = pps_arr[-2]\n",
    "        pps_lag2 = pps_arr[-3]\n",
    "        pps_lag3 = pps_arr[-4]\n",
    "        pps_lag5 = pps_arr[0]\n",
    "\n",
    "        # ventanas sobre TODO el buffer (5 seg)\n",
    "        thr_ma_5  = float(np.nanmean(thr_arr))\n",
    "        thr_std_5 = float(np.nanstd(thr_arr, ddof=1)) if np.isfinite(thr_arr).sum() >= 2 else 0.0\n",
    "        pps_ma_5  = float(np.nanmean(pps_arr))\n",
    "\n",
    "        # pendiente (slope) en 5 s: diff(5)/5\n",
    "        thr_slope5 = (thr_arr[-1] - thr_arr[0]) / 5.0\n",
    "\n",
    "        current = {\n",
    "            \"throughput_bps_t\": thr_arr[-1],\n",
    "            \"pps_t\":            pps_arr[-1],\n",
    "            \"thr_lag1\": thr_lag1, \"thr_lag2\": thr_lag2, \"thr_lag3\": thr_lag3, \"thr_lag5\": thr_lag5,\n",
    "            \"pps_lag1\": pps_lag1, \"pps_lag2\": pps_lag2, \"pps_lag3\": pps_lag3, \"pps_lag5\": pps_lag5,\n",
    "            \"thr_ma_5\": thr_ma_5, \"thr_std_5\": thr_std_5, \"pps_ma_5\": pps_ma_5, \"thr_slope5\": thr_slope5,\n",
    "        }\n",
    "\n",
    "        # Respeta el orden de FEATURES\n",
    "        return np.array([current[k] for k in FEATURES], dtype=float)\n",
    "\n",
    "# ================== HELPERS SQL ==================\n",
    "def fetch_rows_since(since_ts: pd.Timestamp, limit=5000):\n",
    "    \"\"\"\n",
    "    Trae filas nuevas de flow_metrics_logs desde since_ts (exclusivo), ordenadas por ts.\n",
    "    Sólo lo necesario para features: ts, 5-tupla, throughput, packets.\n",
    "    \"\"\"\n",
    "    sql = text(\"\"\"\n",
    "        SELECT\n",
    "          ts,\n",
    "          src_ip::text AS src_ip,\n",
    "          dst_ip::text AS dst_ip,\n",
    "          src_port, dst_port, protocol,\n",
    "          throughput::double precision AS throughput_bps_t,\n",
    "          packets::bigint AS packets\n",
    "        FROM flow_metrics_logs\n",
    "        WHERE ts > :since\n",
    "        ORDER BY ts\n",
    "        LIMIT :lim;\n",
    "    \"\"\")\n",
    "    with ENGINE.connect() as con:\n",
    "        df = pd.read_sql(sql, con, params={\"since\": since_ts, \"lim\": limit})\n",
    "    # Asegurar tz-aware\n",
    "    if not pd.api.types.is_datetime64tz_dtype(df[\"ts\"]):\n",
    "        df[\"ts\"] = pd.to_datetime(df[\"ts\"], utc=True)\n",
    "    return df\n",
    "\n",
    "def save_prediction(row, yhat):\n",
    "    if not SAVE_TO_DB:\n",
    "        return\n",
    "    sql = text(\"\"\"\n",
    "        INSERT INTO throughput_forecast_h1s\n",
    "        (ts, pred_for_ts, src_ip, dst_ip, src_port, dst_port, protocol, yhat_bps_next_1s, model_version)\n",
    "        VALUES (:ts, :pred_ts, :src_ip, :dst_ip, :src_port, :dst_port, :protocol, :yhat, :model_version)\n",
    "    \"\"\")\n",
    "    with ENGINE.begin() as con:\n",
    "        con.execute(sql, {\n",
    "            \"ts\": row[\"ts\"],\n",
    "            \"pred_ts\": row[\"ts\"] + pd.Timedelta(seconds=1),\n",
    "            \"src_ip\": row[\"src_ip\"], \"dst_ip\": row[\"dst_ip\"],\n",
    "            \"src_port\": int(row[\"src_port\"]), \"dst_port\": int(row[\"dst_port\"]),\n",
    "            \"protocol\": int(row[\"protocol\"]),\n",
    "            \"yhat\": float(yhat),\n",
    "            \"model_version\": MODEL_VERSION\n",
    "        })\n",
    "\n",
    "# ================== MAIN LOOP ==================\n",
    "def main():\n",
    "    print(\"Cargando modelo:\", MODEL_PATH)\n",
    "    model = joblib.load(MODEL_PATH)\n",
    "\n",
    "    # Estado por flujo\n",
    "    states: dict[str, FlowState] = defaultdict(FlowState)\n",
    "\n",
    "    # Warmup: arrancamos unos segundos atrás para llenar buffers\n",
    "    now = pd.Timestamp.utcnow().tz_localize(\"UTC\") if pd.Timestamp.utcnow().tzinfo is None else pd.Timestamp.utcnow()\n",
    "    since_ts = now - pd.Timedelta(seconds=WARMUP_SEC)\n",
    "\n",
    "    print(f\"Arrancando desde {since_ts.isoformat()} (warmup {WARMUP_SEC}s).\")\n",
    "    last_seen = since_ts\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            df = fetch_rows_since(last_seen)\n",
    "            if not df.empty:\n",
    "                # procesar en orden cronológico\n",
    "                for _, r in df.iterrows():\n",
    "                    flow_id = f\"{r['src_ip']}:{r['src_port']}>{r['dst_ip']}:{r['dst_port']}/{r['protocol']}\"\n",
    "                    st = states[flow_id]\n",
    "                    # actualizar estado con la muestra actual\n",
    "                    st.update_from_row(r[\"ts\"], r[\"throughput_bps_t\"], r[\"packets\"])\n",
    "\n",
    "                    # construir features si hay buffer suficiente\n",
    "                    x = st.feature_vector()\n",
    "                    if x is not None and np.isfinite(x).all():\n",
    "                        yhat = float(model.predict(x.reshape(1, -1))[0])\n",
    "\n",
    "                        # log consola (en Mbps)\n",
    "                        print(f\"{r['ts']} {flow_id}  thr_now={st.thr[-1]/1e6:.2f} Mbps  \"\n",
    "                              f\"pps={st.pps[-1]:.0f}  yhat(+1s)={yhat/1e6:.2f} Mbps\")\n",
    "\n",
    "                        # persistir (opcional)\n",
    "                        save_prediction(r, yhat)\n",
    "\n",
    "                    # avanzar puntero\n",
    "                    last_seen = max(last_seen, r[\"ts\"])\n",
    "\n",
    "            time.sleep(POLL_SECONDS)\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"Detenido por usuario.\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            # No te quedes mudo si algo se rompe: logueá y seguí\n",
    "            print(\"Error en loop:\", repr(e))\n",
    "            time.sleep(POLL_SECONDS)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
