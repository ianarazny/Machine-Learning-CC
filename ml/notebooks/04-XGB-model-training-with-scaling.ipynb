{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04354d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score, classification_report, average_precision_score\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aed65893",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SELECTED_FEATURES = ['cwnd', 'rtt', 'bytes_retrans', 'bytes_acked', 'throughput', 'packets_lost']\n",
    "\n",
    "# Las tratamos as√≠:\n",
    "# - Contadores pesados (log1p): bytes_retrans, bytes_acked, packets_lost\n",
    "# - Continuas (z-score opcional): cwnd, rtt, throughput\n",
    "CONTADORES = ['bytes_retrans', 'bytes_acked', 'packets_lost']\n",
    "CONTINUAS  = ['cwnd', 'rtt', 'throughput']\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.20\n",
    "\n",
    "xgb_params = dict(\n",
    "    tree_method='hist',\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    eval_metric='logloss',\n",
    "    n_jobs=-1,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f2c88f",
   "metadata": {},
   "source": [
    "\n",
    "## Cargar datos\n",
    "\n",
    "Reemplaz√° la celda siguiente por tu propio *loader* si us√°s el de `scripts/data_loader.py`.\n",
    "El notebook intenta detectar un CSV t√≠pico de BBR como ejemplo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a01d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "base_dir = '../data_processed'\n",
    "all_data = []\n",
    "\n",
    "for root, dirs, files in os.walk(base_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.csv'):\n",
    "            path = os.path.join(root, file)\n",
    "            df = pd.read_csv(path)\n",
    "            df['variant'] = os.path.basename(root)  #  a√±adir columna con el nombre de la variante\n",
    "            all_data.append(df)\n",
    "\n",
    "# Concatenar todos los DataFrames\n",
    "df_all = pd.concat(all_data, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca726d8d",
   "metadata": {},
   "source": [
    "\n",
    "## Etiquetado y selecci√≥n de columnas\n",
    "\n",
    "Si ya ten√©s una columna de etiqueta (`congestion_event`), el c√≥digo la utilizar√°.\n",
    "Si no existe, por defecto construye una etiqueta simple basada en una ca√≠da de `cwnd` (ejemplo para BBR)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018dd40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Etiqueta: usar la existente o construir una simple basada en cwnd\n",
    "if 'congestion_event' not in df.columns and 'cwnd' in df.columns:\n",
    "    df['congestion_event'] = (df['cwnd'].diff().shift(-1) < -10).astype(int)\n",
    "\n",
    "# Filtrar filas/columnas necesarias\n",
    "needed = [c for c in SELECTED_FEATURES if c in df.columns]\n",
    "if 'congestion_event' in df.columns:\n",
    "    needed = needed + ['congestion_event']\n",
    "\n",
    "df = df[needed].dropna()\n",
    "print(\"Usando columnas:\", needed)\n",
    "print(\"Shape despu√©s de filtrar:\", df.shape)\n",
    "\n",
    "assert 'congestion_event' in df.columns, \"No se encontr√≥ la etiqueta 'congestion_event'. A√±adila o ajust√° esta celda.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4c3c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df[SELECTED_FEATURES].copy()\n",
    "y = df['congestion_event'].astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, stratify=y, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(\"Train:\", X_train.shape, \"Test:\", X_test.shape, \"Positives in test:\", int(y_test.sum()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6242fe79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Intersecciones seguras por si alguna columna no est√°\n",
    "CONTADORES_IN = [c for c in CONTADORES if c in X_train.columns]\n",
    "CONTINUAS_IN  = [c for c in CONTINUAS  if c in X_train.columns]\n",
    "\n",
    "pre_no_scale = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('log_counts', FunctionTransformer(np.log1p, feature_names_out='one-to-one'), CONTADORES_IN)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "pre_zscore = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('log_counts', FunctionTransformer(np.log1p, feature_names_out='one-to-one'), CONTADORES_IN),\n",
    "        ('std_cont', StandardScaler(), CONTINUAS_IN)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "clf_no_scale = Pipeline([('pre', pre_no_scale), ('xgb', XGBClassifier(**xgb_params))])\n",
    "clf_zscore  = Pipeline([('pre', pre_zscore),  ('xgb', XGBClassifier(**xgb_params))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2920407b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate(clf, X_tr, y_tr, X_te, y_te, name=\"model\"):\n",
    "    clf.fit(X_tr, y_tr)\n",
    "    prob = clf.predict_proba(X_te)[:, 1]\n",
    "    # thresholds candidatos: todos los prob √∫nicos + 0/0.5/1 para robustez\n",
    "    thresholds = np.unique(np.concatenate(([0.0, 0.5, 1.0], prob)))\n",
    "    best_f1, best_t, best_pred = -1.0, 0.5, None\n",
    "    for t in thresholds:\n",
    "        pred = (prob >= t).astype(int)\n",
    "        f1 = f1_score(y_te, pred, zero_division=0)\n",
    "        if f1 > best_f1:\n",
    "            best_f1, best_t, best_pred = f1, t, pred\n",
    "    ap = average_precision_score(y_te, prob)\n",
    "    print(f\"[{name}] Best F1: {best_f1:.4f} @ threshold={best_t:.3f} | AP={ap:.4f}\")\n",
    "    print(classification_report(y_te, best_pred, digits=2))\n",
    "    return {'clf': clf, 'prob': prob, 'best_t': float(best_t), 'best_f1': float(best_f1), 'ap': float(ap)}\n",
    "\n",
    "res_no = evaluate(clf_no_scale, X_train, y_train, X_test, y_test, name='log1p-only')\n",
    "res_z  = evaluate(clf_zscore,  X_train, y_train, X_test, y_test, name='zscore+log1p')\n",
    "\n",
    "best = res_z if res_z['best_f1'] >= res_no['best_f1'] else res_no\n",
    "best_name = 'zscore+log1p' if best is res_z else 'log1p-only'\n",
    "print(\"‚úÖ Selected pipeline:\", best_name)\n",
    "\n",
    "best_clf = best['clf']\n",
    "best_t = best['best_t']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45acd53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "joblib.dump(best_clf, 'xgb_pipeline_bbr.joblib')\n",
    "with open('xgb_threshold.json', 'w') as f:\n",
    "    json.dump({'threshold': best_t, 'pipeline': 'zscore+log1p' if best_clf is clf_zscore else 'log1p-only'}, f, indent=2)\n",
    "print(\"üíæ Guardado: xgb_pipeline_bbr.joblib, xgb_threshold.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e844bd",
   "metadata": {},
   "source": [
    "\n",
    "## Notas\n",
    "- **Solo se usan**: `cwnd`, `rtt`, `bytes_retrans`, `bytes_acked`, `throughput`, `packets_lost`.\n",
    "- `log1p` mitiga colas pesadas/outliers en contadores; `z-score` aporta comparabilidad y estabilidad num√©rica en las continuas.\n",
    "- El pipeline mantiene **reproducibilidad** y evita *data leakage* (transformaciones ajustadas solo en train).\n",
    "- Se sigue la receta de *feature engineering ‚Üí entrenamiento* destacada en *ML for Networking*.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
