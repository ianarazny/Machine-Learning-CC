{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "connection to server at \"localhost\" (::1), port 15432 failed: Connection refused (0x0000274D/10061)\n\tIs the server running on that host and accepting TCP/IP connections?\nconnection to server at \"localhost\" (127.0.0.1), port 15432 failed: Connection refused (0x0000274D/10061)\n\tIs the server running on that host and accepting TCP/IP connections?\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOperationalError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# ---------- 2.1 Carga ----------\u001b[39;00m\n\u001b[32m     21\u001b[39m QUERY = \u001b[33m\"\"\"\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[33mSELECT ts_1s AS ts, src_ip, dst_ip, src_port, dst_port, protocol,\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[33m       throughput_bps_t, pps_t, y_bps_next_1s\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     26\u001b[39m \u001b[33mORDER BY ts_1s;\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mpsycopg2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mCONN\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m con:\n\u001b[32m     29\u001b[39m     df = pd.read_sql(QUERY, con)\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# clave de flujo\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ian\\Desktop\\fing\\tesis\\Machine-Learning-CC\\venv\\Lib\\site-packages\\psycopg2\\__init__.py:135\u001b[39m, in \u001b[36mconnect\u001b[39m\u001b[34m(dsn, connection_factory, cursor_factory, **kwargs)\u001b[39m\n\u001b[32m    132\u001b[39m     kwasync[\u001b[33m'\u001b[39m\u001b[33masync_\u001b[39m\u001b[33m'\u001b[39m] = kwargs.pop(\u001b[33m'\u001b[39m\u001b[33masync_\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    134\u001b[39m dsn = _ext.make_dsn(dsn, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m conn = \u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnection_factory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconnection_factory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwasync\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cursor_factory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    137\u001b[39m     conn.cursor_factory = cursor_factory\n",
      "\u001b[31mOperationalError\u001b[39m: connection to server at \"localhost\" (::1), port 15432 failed: Connection refused (0x0000274D/10061)\n\tIs the server running on that host and accepting TCP/IP connections?\nconnection to server at \"localhost\" (127.0.0.1), port 15432 failed: Connection refused (0x0000274D/10061)\n\tIs the server running on that host and accepting TCP/IP connections?\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "import joblib\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "CONN = dict(\n",
    "    host=os.getenv(\"DB_HOST\"),\n",
    "    port=os.getenv(\"DB_PORT\"),\n",
    "    dbname=os.getenv(\"DB_NAME\"),\n",
    "    user=os.getenv(\"DB_USER\"),\n",
    "    password=os.getenv(\"DB_PASSWORD\"),\n",
    ")\n",
    "# ---------- 2.1 Carga ----------\n",
    "QUERY = \"\"\"\n",
    "SELECT ts_1s AS ts, src_ip, dst_ip, src_port, dst_port, protocol,\n",
    "       throughput_bps_t, pps_t, y_bps_next_1s\n",
    "FROM training_bps_h1s\n",
    "WHERE ts_1s IS NOT NULL\n",
    "ORDER BY ts_1s;\n",
    "\"\"\"\n",
    "with psycopg2.connect(**CONN) as con:\n",
    "    df = pd.read_sql(QUERY, con)\n",
    "\n",
    "# clave de flujo\n",
    "df[\"flow_id\"] = (df[\"src_ip\"].astype(str) + \":\" + df[\"src_port\"].astype(str) + \">\" +\n",
    "                 df[\"dst_ip\"].astype(str) + \":\" + df[\"dst_port\"].astype(str) + \"/\" +\n",
    "                 df[\"protocol\"].astype(str))\n",
    "\n",
    "\n",
    "# ---------- 2.2 Lags y ventanas por flujo ----------\n",
    "def add_lags_rolls(g):\n",
    "    g = g.sort_values(\"ts\")\n",
    "    for k in [1,2,3,5]:\n",
    "        g[f\"throughput_lag{k}\"] = g[\"throughput_bps_t\"].shift(k)\n",
    "        g[f\"pps_lag{k}\"]        = g[\"pps_t\"].shift(k)\n",
    "    # rolling sobre pasado (window=5s)\n",
    "    g[\"thr_ma_5\"]  = g[\"throughput_bps_t\"].rolling(window=5, min_periods=1).mean()\n",
    "    g[\"thr_std_5\"] = g[\"throughput_bps_t\"].rolling(window=5, min_periods=2).std()\n",
    "    g[\"pps_ma_5\"]  = g[\"pps_t\"].rolling(window=5, min_periods=1).mean()\n",
    "    # pendiente (slope) simple sobre 5s\n",
    "    g[\"thr_slope_5\"] = g[\"throughput_bps_t\"].diff(5) / 5.0\n",
    "    return g\n",
    "\n",
    "df = df.groupby(\"flow_id\", group_keys=False).apply(add_lags_rolls)\n",
    "\n",
    "# quitar filas con NaN por lags al inicio\n",
    "df = df.dropna()\n",
    "\n",
    "FEATURES = [\n",
    "    \"throughput_bps_t\",\"pps_t\",\n",
    "    \"throughput_lag1\",\"throughput_lag2\",\"throughput_lag3\",\"throughput_lag5\",\n",
    "    \"pps_lag1\",\"pps_lag2\",\"pps_lag3\",\"pps_lag5\",\n",
    "    \"thr_ma_5\",\"thr_std_5\",\"pps_ma_5\",\"thr_slope_5\"\n",
    "]\n",
    "TARGET = \"y_bps_next_1s\"\n",
    "X = df[FEATURES].values\n",
    "y = df[TARGET].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL 1s → MAE=1,222,011,563 bps  |  RMSE=2,984,995,950 bps\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['xgb_bps_h1s.joblib']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split temporal: último 20% como validación\n",
    "cut = int(len(df) * 0.8)\n",
    "X_tr, y_tr = X[:cut], y[:cut]\n",
    "X_va, y_va = X[cut:], y[cut:]\n",
    "\n",
    "model = XGBRegressor(\n",
    "    objective=\"reg:squarederror\",\n",
    "    tree_method=\"hist\",\n",
    "    n_estimators=600,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_tr, y_tr,\n",
    "          eval_set=[(X_va, y_va)],\n",
    "          verbose=False)\n",
    "\n",
    "pred_va = model.predict(X_va)\n",
    "\n",
    "mae  = mean_absolute_error(y_va, pred_va)\n",
    "\n",
    "# Compatibilidad con cualquier versión de sklearn\n",
    "try:\n",
    "    rmse = mean_squared_error(y_va, pred_va, squared=False)\n",
    "except TypeError:\n",
    "    rmse = np.sqrt(mean_squared_error(y_va, pred_va))\n",
    "\n",
    "print(f\"VAL 1s → MAE={mae:,.0f} bps  |  RMSE={rmse:,.0f} bps\")\n",
    "\n",
    "\n",
    "joblib.dump(model, \"xgb_bps_h1s.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicción throughput (siguiente 1s) para 10.0.0.1:5201>10.0.0.2:58628/6: 114 bps\n"
     ]
    }
   ],
   "source": [
    "# tomemos el último timestamp de un flujo cualquiera (o uno en particular)\n",
    "flow = df[\"flow_id\"].iloc[-1]\n",
    "last_row = df[df[\"flow_id\"]==flow].sort_values(\"ts\").iloc[-1]\n",
    "\n",
    "x_now = last_row[FEATURES].values.reshape(1, -1)\n",
    "yhat_1s = model.predict(x_now)[0]\n",
    "print(f\"Predicción throughput (siguiente 1s) para {flow}: {yhat_1s:,.0f} bps\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
